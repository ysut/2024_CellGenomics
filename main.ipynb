{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "apt install bedtools\n",
    "which intersectBed\n",
    "git clone https://github.com/ysut/2024_CellGenmics.git\n",
    "pip install gffutils pandas pandarallel pysam tqdm biopython pybedtools liftover\n",
    "anno_db=\"https://zenodo.org/records/13310274/files/gencode.v43lift37.annotation.gtf.db\"\n",
    "anno_int_db=\"https://zenodo.org/records/13310274/files/gencode.v43lift37.annotation.intron.gtf.db\"\n",
    "wget -c -P /content/2024_CellGenomics/resources/06_gffutilsdb \"${anno_db}\"\n",
    "wget -c -P /content/2024_CellGenomics/resources/06_gffutilsdb \"${anno_int_db}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/2024_CellGenomics/')\n",
    "import yaml\n",
    "from logging import getLogger, config\n",
    "\n",
    "import gffutils\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import pysam\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lib import utils, posparser, splaiparser, predeffect, anno_clinvar\n",
    "from lib.scoring import Scoring\n",
    "\n",
    "########   Initialize and setup pandas methods   ########\n",
    "pandarallel.initialize(\n",
    "    nb_workers=os.cpu_count()-1, progress_bar=False, verbose=2, use_memory_fs=False) \n",
    "os.environ['JOBLIB_TEMP_FOLDER'] = '/tmp' \n",
    "tqdm.pandas()\n",
    "\n",
    "########   Logging setup   ########\n",
    "parent_directory = os.path.dirname(os.path.dirname('__file__'))\n",
    "config_path: str = os.path.join(parent_directory, 'config/logging.yaml')\n",
    "with open(config_path, 'r') as f:\n",
    "    config.dictConfig(yaml.safe_load(f))\n",
    "logger = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "########   Import genocode DBs (exon DB and intron DB)   ########\n",
    "db_anno_gencode = 'resources/06_gffutilsdb/gencode.v43lift37.annotation.gtf.db'\n",
    "db_anno_intron = 'resources/06_gffutilsdb/gencode.v43lift37.annotation.intron.gtf.db'\n",
    "db = gffutils.FeatureDB(db_anno_gencode)\n",
    "db_intron = gffutils.FeatureDB(db_anno_intron)\n",
    "\n",
    "########   Import resource files   ########\n",
    "#1. Clinvar variants (BED format)\n",
    "clinvar_file = 'resources/03_ClinVar/variant_summary.snv.grch37.germline.criteria.sort.bed.gz'\n",
    "tbx_clinvar = pysam.TabixFile(clinvar_file)\n",
    "#2. GENCODE file (GFF3 format)\n",
    "gencode_gff = 'resources/05_GENCODE_v43lift37/gencode.v43lift37.annotation.sort.gff3.gz'\n",
    "tbx_anno = pysam.TabixFile(gencode_gff)\n",
    "\n",
    "## Thresholds configuration\n",
    "thresholds_SpliceAI_parser: dict = {\n",
    "    'TH_min_sALDL': 0.02, 'TH_max_sALDL': 0.2, \n",
    "    'TH_min_sAGDG': 0.01, 'TH_max_sAGDG': 0.05,\n",
    "    'TH_min_GExon': 25, 'TH_max_GExon': 500,\n",
    "    'TH_sAG': 0.2, 'TH_sDG': 0.2\n",
    "    }\n",
    "\n",
    "sccore_ths = {'clinvar_same_pos': 2,     \n",
    "              'clinvar_same_motif': 1,\n",
    "              'clinvar_else': 0,\n",
    "              'non_canon_splai_lte_0.1_outside': -3,\n",
    "              'non_canon_splai_lte_0.1_other': -2,\n",
    "              'non_canon_splai_bet_0.1_0.2': 1,\n",
    "              'non_canon_splai_gte_0.2': 2,\n",
    "              'canon_strong': 6, \n",
    "              'canon_moderate': 5, \n",
    "              'frameshift_nmd_eloF': 7, \n",
    "              'frameshift_nmd_not_eloF': 3,\n",
    "              'canon_splai_lte_0.1': -3,\n",
    "              'canon_splai_bet_0.1_0.2': -1,\n",
    "              'canon_splai_gte_0.2': 0}\n",
    "\n",
    "# Two example pickle files are provided in the 'cohort' folder\n",
    "mydata_pickle = 'cohort/example_cases_1.pkl'\n",
    "#mydata_pickle = 'cohort/example_cases_2.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De novo detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(mydata_pickle)\n",
    "df = df[df['vqslod'] > -7.18]\n",
    "df = df[((df['denovogear'] > 0.02) | (df['denovogear'].isnull()))\n",
    "        & ((df['triodenovo'] > 5.72) | (df['triodenovo'].isnull()))\n",
    "        & ((df['dnmfilter'] > 0.196) | (df['dnmfilter'].isnull()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify 'Canonical' splice site or 'Non-canonical' splice site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Classify \"Canonical\" splice site or \"Non-canonical\" splice site...')\n",
    "df = posparser.classifying_canonical(df, cdot='c.HGVS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate exonic positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Calculating exonic positions...')\n",
    "\n",
    "#2-1. Generate 'exonic upstream distance and exonic downstream distance\n",
    "df['exon_loc'] = df.progress_apply(\n",
    "    posparser.calc_exon_loc, tabixfile=tbx_anno, enstcolname='ENST', axis=1)\n",
    "df = pd.concat([df, df['exon_loc'].str.split(':', expand=True)], axis=1)\n",
    "df.rename(columns={0: 'ex_up_dist', 1: 'ex_down_dist'}, inplace=True)\n",
    "\n",
    "#2-2. Select minimum distance from upstream distance and downstream distance\n",
    "df['exon_pos'] = df.parallel_apply(posparser.select_exon_pos, axis=1)\n",
    "\n",
    "#2-3. Decision exonic splice sites (1 nt in acceptor site or 3 nts on Donor site)\n",
    "df['exon_splice_site'] = df.parallel_apply(\n",
    "    posparser.extract_splicing_region, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Splicing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Annotating splicing information...')\n",
    "\n",
    "#3-1. Annotate splicing type ('Exonic Acceptor' etc.)\n",
    "df['SpliceType'] = df.parallel_apply(\n",
    "    posparser.select_donor_acceptor, axis=1)\n",
    "\n",
    "#3-2. Annotate rank of exon or intron\n",
    "df['Num_ExInt'] = df.progress_apply(\n",
    "    posparser.calc_ex_int_num, db=db, db_intron=db_intron, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate ClinVar varaints interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Annotating ClinVar varaints interpretations...')\n",
    "df['clinvar_same_pos'] = df.progress_apply(\n",
    "    anno_clinvar.anno_same_pos_vars, tabixfile=tbx_clinvar, axis=1)\n",
    "df['clinvar_same_motif'] = df.progress_apply(\n",
    "    anno_clinvar.anno_same_motif_vars, tabixfile=tbx_clinvar, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parising SpliceAI results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Parsing SpliceAI results...')\n",
    "\n",
    "#5-1. Annotate Exon/Intron position information\n",
    "df['ExInt_INFO'] = df.progress_apply(splaiparser.calc_exint_info, \n",
    "                                     db=db, \n",
    "                                     db_intron=db_intron, \n",
    "                                     axis=1)\n",
    "\n",
    "#5-2. Relative exon location\n",
    "df['prc_exon_loc'] = df.parallel_apply(posparser.calc_prc_exon_loc, axis=1)\n",
    "\n",
    "\n",
    "#5-3. Predict splicing effects\n",
    "df['Pseudoexon'] = df.progress_apply(\n",
    "    splaiparser.pseudoexon_activation,\n",
    "    thresholds=thresholds_SpliceAI_parser, \n",
    "    db_intron=db_intron,\n",
    "    axis=1)\n",
    "\n",
    "df['Part_IntRet'] = df.parallel_apply(\n",
    "    splaiparser.partial_intron_retention,\n",
    "    thresholds=thresholds_SpliceAI_parser, \n",
    "    axis=1)\n",
    "\n",
    "df['Part_ExDel'] = df.parallel_apply(\n",
    "    splaiparser.partial_exon_deletion,\n",
    "    thresholds=thresholds_SpliceAI_parser, \n",
    "    axis=1)\n",
    "\n",
    "df['Exon_skipping'] = df.parallel_apply(\n",
    "    splaiparser.exon_skipping, \n",
    "    thresholds=thresholds_SpliceAI_parser, \n",
    "    axis=1)\n",
    "                                        \n",
    "df['Int_Retention'] = df.parallel_apply(\n",
    "    splaiparser.intron_retention, \n",
    "    thresholds=thresholds_SpliceAI_parser, \n",
    "    axis=1)\n",
    "\n",
    "df['multiexs'] = df.parallel_apply(\n",
    "    splaiparser.multi_exon_skipping, \n",
    "    thresholds=thresholds_SpliceAI_parser, \n",
    "    axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate aberrant splicing size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Annotating aberrant splicing size (bp)...')\n",
    "#6-1. Annotate size of \n",
    "df['Size_Part_ExDel'] = df.parallel_apply(\n",
    "    splaiparser.anno_partial_exon_del_size, \n",
    "    thresholds=thresholds_SpliceAI_parser, \n",
    "    axis=1)\n",
    "\n",
    "#6-2. Annotate size of partial intron retention\n",
    "df['Size_Part_IntRet'] = df.parallel_apply(\n",
    "    splaiparser.anno_partial_intron_retention_size, \n",
    "    thresholds=thresholds_SpliceAI_parser,\n",
    "    axis=1)\n",
    "\n",
    "#6-3. Annotate size of pseudoexon\n",
    "df['Size_pseudoexon'] = df.parallel_apply(\n",
    "    splaiparser.anno_gained_exon_size, \n",
    "    thresholds=thresholds_SpliceAI_parser, \n",
    "    axis=1)\n",
    "\n",
    "#6-4. Annotate size of intron retention\n",
    "df['Size_IntRet'] = df.parallel_apply(\n",
    "    splaiparser.anno_intron_retention_size, \n",
    "    thresholds=thresholds_SpliceAI_parser,\n",
    "    axis=1)\n",
    "\n",
    "#6-5. Annotate size of exon skipping\n",
    "df['Size_skipped_exon'] = df.parallel_apply(\n",
    "    splaiparser.anno_skipped_exon_size, \n",
    "    thresholds=thresholds_SpliceAI_parser,\n",
    "    axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate splicing effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Predicting CDS change...')\n",
    "#7-1. Predict CDS change\n",
    "df['CDS_Length'] = df.progress_apply(predeffect.calc_cds_len, db=db, axis=1)\n",
    "df['is_10%_truncation'] = df.progress_apply(predeffect.calc_cds_len_shorten, axis=1)\n",
    "\n",
    "#7-2. Determine if the gene is included in eLoFs genes\n",
    "df['is_eLoF'] = df.parallel_apply(predeffect.elofs_judge, axis=1)\n",
    "\n",
    "#7-3. Determine causing NMD or not\n",
    "df['is_NMD_at_Canon'] = df.parallel_apply(predeffect.nmd_judge, axis=1)\n",
    "\n",
    "#7-4. Frame check\n",
    "df['is_Frameshift_Part_ExDel'] = df['Size_Part_ExDel'].parallel_apply(\n",
    "    predeffect.frame_check)\n",
    "df['is_Frameshift_Part_IntRet'] = df['Size_Part_IntRet'].parallel_apply(\n",
    "    predeffect.frame_check)\n",
    "df['is_Frameshift_pseudoexon'] = df['Size_pseudoexon'].parallel_apply(\n",
    "    predeffect.frame_check)\n",
    "df['is_Frameshift_IntRet'] = df['Size_IntRet'].parallel_apply(\n",
    "    predeffect.frame_check)\n",
    "df['is_Frameshift_skipped_exon'] = df['Size_skipped_exon'].parallel_apply(\n",
    "    predeffect.frame_check)\n",
    "df['is_Frameshift'] = df[['is_Frameshift_Part_ExDel', \n",
    "                          'is_Frameshift_Part_IntRet', \n",
    "                          'is_Frameshift_pseudoexon', \n",
    "                          'is_Frameshift_IntRet', \n",
    "                          'is_Frameshift_skipped_exon'\n",
    "                          ]].any(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CCRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Annotating CCRs info...')\n",
    "\n",
    "#8-1. Annotate truncated regions \n",
    "df['skipped_region'] = df.parallel_apply(\n",
    "    splaiparser.anno_skipped_regions, axis=1)\n",
    "\n",
    "df['deleted_region'] = df.parallel_apply(\n",
    "    splaiparser.anno_deleted_regions, \n",
    "    thresholds=thresholds_SpliceAI_parser, axis=1)\n",
    "\n",
    "#8-2. Intersect with CCRs\n",
    "logger.info('Annotate CCR scores...')\n",
    "df = predeffect.anno_ccr_score(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate priority scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Annotating priority scores...')\n",
    "scoring = Scoring(ths=sccore_ths)\n",
    "df = df.astype({'maxsplai': 'float', 'vqslod': 'float', \n",
    "                'denovogear': float, 'triodenovo': float, 'dnmfilter': float})\n",
    "df['insilico_screening'] = df.parallel_apply(scoring.insilico_screening, axis=1)\n",
    "df['clinvar_screening'] = df.parallel_apply(scoring.clinvar_screening, axis=1)\n",
    "df = scoring.calc_priority_score(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
